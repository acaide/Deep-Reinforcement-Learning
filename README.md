# Deep-Reinforcement-Learning
CSCI S-89C - Deep Reinforcement Learning - Summer 2020


## Course Description:

This course introduces Deep Reinforcement Learning (RL), one of the most modern techniques of machine learning. 

Reinforcement Learning (RL) is often seen as the third area of machine learning, in addition to supervised and unsupervised algorithms, in which learning of an agent occurs as a result of its own actions and interaction with the environment. Generally, such learning processes do not need to be guided externally, but it has been difficult until recently to use RL ideas practically. 

This course primarily focuses on problems that emerge in healthcare and life science applications. Each assignment has a theoretical (pen and paper) component and a practical (jupyter notebook) component.

This course has a a mid-term and final test in leu of a final project.

Problem sets aren't perfect; they reflect my understanding of the material at the time they were submitted. **Note**: While this course is officially called 'Deep RL', neural networks were implemented towards the very end of the course in the last two lectures + homework assignment. 

## Assignments:

1. Introduction to reinforcement the learning lanscape (environments, agents, and rewards), and E-Greedy (epsiolon greedy) selection method and model evaluation.
2. Markov Decision Process (MDP), the n-armed Bandit Problem, the gradient bandit algorithm, alpha value exploration.  
3. MDP with transition probabilities and policies, state value estimations, the Bellman Equation
4. First-Visit Monte Carlo (MC) predicion and evaluation, MC Control methods, E-soft policies.
5. Off policy MC control (policy estimation)
6. State value function estimation, (one-step) Temporal Difference (TD) predictions, Double Q-learning
7. Semi-gradient TD predictions
8. Tabular TD (ùúÜ) to estimate value function, with a ùúÜ-return algorithm. TD with approrximation, and tabular 1-step TD.
9. Q-learning with approximation, experience replay, action-state value estimation. Tabular Q-learning.
10. State-value apprximation via semi-gradient 1-step TD algorithm with experience replay, with provided state-value approximations.
11. Deep Reinforcement learning with Keras; Double Q learning with apprximation via Deep NN. 
